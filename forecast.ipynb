{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3365e8-ca67-41ea-8359-4f0e203972d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 09:32:20.111497: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-10 09:32:22.108258: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     date  temperature  NUM_POSTE     LAT       LON  \\\n",
      "0     2023-01-01 00:00:00         11.0   20004002  41.918  8.792667   \n",
      "1     2023-01-01 01:00:00         10.4   20004002  41.918  8.792667   \n",
      "2     2023-01-01 02:00:00          9.9   20004002  41.918  8.792667   \n",
      "3     2023-01-01 03:00:00          9.6   20004002  41.918  8.792667   \n",
      "4     2023-01-01 04:00:00          9.7   20004002  41.918  8.792667   \n",
      "...                   ...          ...        ...     ...       ...   \n",
      "12311 2024-05-27 23:00:00         17.6   20004002  41.918  8.792667   \n",
      "12312 2024-05-28 00:00:00         16.0   20004002  41.918  8.792667   \n",
      "12313 2024-05-28 01:00:00         15.4   20004002  41.918  8.792667   \n",
      "12314 2024-05-28 02:00:00         15.0   20004002  41.918  8.792667   \n",
      "12315 2024-05-28 03:00:00         13.5   20004002  41.918  8.792667   \n",
      "\n",
      "       temperature_station1  temperature_station2  temperature_station3  \\\n",
      "0                      14.6                  11.0                  11.9   \n",
      "1                      13.6                  10.7                  12.7   \n",
      "2                      13.5                  10.7                  12.2   \n",
      "3                      13.9                  10.6                  13.0   \n",
      "4                      13.3                  10.5                  13.2   \n",
      "...                     ...                   ...                   ...   \n",
      "12311                  19.2                  15.5                  17.6   \n",
      "12312                  19.6                  14.7                  16.5   \n",
      "12313                  18.7                  14.1                  16.2   \n",
      "12314                  18.1                  14.2                  16.4   \n",
      "12315                  18.1                  14.0                  16.6   \n",
      "\n",
      "       temperature_scaled  temperature_scaled1  temperature_scaled2  \\\n",
      "0                0.288095             0.373810             0.288095   \n",
      "1                0.273810             0.350000             0.280952   \n",
      "2                0.261905             0.347619             0.280952   \n",
      "3                0.254762             0.357143             0.278571   \n",
      "4                0.257143             0.342857             0.276190   \n",
      "...                   ...                  ...                  ...   \n",
      "12311            0.445238             0.483333             0.395238   \n",
      "12312            0.407143             0.492857             0.376190   \n",
      "12313            0.392857             0.471429             0.361905   \n",
      "12314            0.383333             0.457143             0.364286   \n",
      "12315            0.347619             0.457143             0.359524   \n",
      "\n",
      "       temperature_scaled3  \n",
      "0                 0.309524  \n",
      "1                 0.328571  \n",
      "2                 0.316667  \n",
      "3                 0.335714  \n",
      "4                 0.340476  \n",
      "...                    ...  \n",
      "12311             0.445238  \n",
      "12312             0.419048  \n",
      "12313             0.411905  \n",
      "12314             0.416667  \n",
      "12315             0.421429  \n",
      "\n",
      "[12316 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Input, Bidirectional, Concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimpy import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.interpolate import CubicSpline\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "num_stations=3\n",
    "data = pd.read_csv(\"meteofrance.csv\", sep = \";\")\n",
    "ss = np.unique(data['NUM_POSTE'].values)\n",
    "colonnes_a_garder = ['AAAAMMJJHH',  ' T', 'NUM_POSTE', 'LAT', 'LON']\n",
    "df = data.loc[:,colonnes_a_garder].copy()  # Création d'une copie\n",
    "df.loc[:, 'AAAAMMJJHH'] = pd.to_datetime(df['AAAAMMJJHH'], format='%Y%m%d%H')\n",
    "df.rename(columns={\n",
    "    'AAAAMMJJHH' : 'date',\n",
    "    ' T': 'temperature'\n",
    "}, inplace=True)\n",
    "df1 = df.loc[df['NUM_POSTE'] == 20004002]\n",
    "\n",
    "start_column = 7\n",
    "max_hole=6\n",
    "N=10\n",
    "tab_hole=[1,2,3,4,5,6]\n",
    "column='temperature'\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0  # Rayon de la Terre en kilomètres\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    a = sin(dlat / 2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "main_station = df.loc[df['NUM_POSTE'] == 20004002].copy()\n",
    "unique_stations = df.drop_duplicates(subset=['NUM_POSTE'])\n",
    "lat1, lon1 = main_station['LAT'].values[0], main_station['LON'].values[0]\n",
    "unique_stations['distance'] = unique_stations.apply(lambda row: haversine(lat1, lon1, row['LAT'], row['LON']), axis=1)\n",
    "neighbor_stations = unique_stations[unique_stations['NUM_POSTE'] != 20004002].sort_values('distance').head(num_stations)\n",
    "neighbor_stations = np.unique(neighbor_stations['NUM_POSTE'].values)\n",
    "#print(neighbor_stations)\n",
    "i=1\n",
    "for station in neighbor_stations:\n",
    "    station_data = df.loc[df['NUM_POSTE'] == station, ['date', 'temperature']].rename(columns={'temperature': f'temperature_station{i}'})\n",
    "    i=i+1\n",
    "    df1 = df1.merge(station_data, on='date', how='left')\n",
    "    \n",
    "combined_temps = np.concatenate([df1['temperature'].values] + [df1[f'temperature_station{j}'].values for j in range(1, i)])\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(combined_temps.reshape(-1, 1))\n",
    "\n",
    "df1['temperature_scaled'] = scaler.transform(df1[['temperature']])\n",
    "for j in range(1, i):\n",
    "    df1[f'temperature_scaled{j}'] = scaler.transform(df1[[f'temperature_station{j}']])\n",
    "rows_with_nan = df1[df1.isna().any(axis=1)].index.tolist()\n",
    "rows_with_nan.insert(0, -1)\n",
    "rows_with_nan.append(len(df1))\n",
    "df1.interpolate(method='linear', inplace=True)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d90e3f9-c18b-4f1e-b977-a5045942dc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2757732  0.24226804 0.23969072 ... 0.42525773 0.41494845 0.37628866]\n",
      "Epoch 1/50\n",
      "154/154 - 3s - 19ms/step - loss: 0.0204 - val_loss: 0.0077\n",
      "Epoch 2/50\n",
      "154/154 - 1s - 8ms/step - loss: 0.0058 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "154/154 - 1s - 8ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 4/50\n",
      "154/154 - 1s - 8ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 5/50\n",
      "154/154 - 1s - 8ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 6/50\n",
      "154/154 - 1s - 8ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 7/50\n",
      "154/154 - 1s - 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "154/154 - 1s - 8ms/step - loss: 0.0011 - val_loss: 9.4583e-04\n",
      "Epoch 9/50\n",
      "154/154 - 1s - 8ms/step - loss: 0.0011 - val_loss: 9.1496e-04\n",
      "Epoch 10/50\n",
      "154/154 - 1s - 8ms/step - loss: 9.5297e-04 - val_loss: 8.0290e-04\n",
      "Epoch 11/50\n",
      "154/154 - 1s - 8ms/step - loss: 8.4454e-04 - val_loss: 7.3696e-04\n",
      "Epoch 12/50\n",
      "154/154 - 1s - 8ms/step - loss: 7.9788e-04 - val_loss: 8.0862e-04\n",
      "Epoch 13/50\n",
      "154/154 - 1s - 8ms/step - loss: 7.8789e-04 - val_loss: 7.3211e-04\n",
      "Epoch 14/50\n",
      "154/154 - 1s - 8ms/step - loss: 7.5750e-04 - val_loss: 7.5340e-04\n",
      "Epoch 15/50\n",
      "154/154 - 1s - 8ms/step - loss: 7.1250e-04 - val_loss: 6.2103e-04\n",
      "Epoch 16/50\n",
      "154/154 - 1s - 8ms/step - loss: 6.9453e-04 - val_loss: 5.9928e-04\n",
      "Epoch 17/50\n",
      "154/154 - 1s - 8ms/step - loss: 6.5663e-04 - val_loss: 6.0008e-04\n",
      "Epoch 18/50\n",
      "154/154 - 1s - 9ms/step - loss: 6.5442e-04 - val_loss: 0.0010\n",
      "Epoch 19/50\n",
      "154/154 - 1s - 8ms/step - loss: 6.7167e-04 - val_loss: 7.1382e-04\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f02200d21d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "data = df1[['temperature']]  \n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "def create_dataset(dataset, look_back=24):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i + look_back), 0]  # Utilisation de la seule colonne\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])  # Utilisation de la même colonne pour y\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "X, y = create_dataset(data_scaled, look_back=24)\n",
    "print(y)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model.fit(trainX, trainY, epochs=50, batch_size=64,callbacks=[early_stop], validation_data=(testX, testY), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd15daf-b3b1-4c21-9aff-a89644cb0c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"forecast_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70d491-824a-41ab-a617-d223da60e174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
